{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution() # this is necessary in audi8\n",
    "import tensorflow_federated as tff\n",
    "import nest_asyncio # this is necessary in audi 9 \n",
    "nest_asyncio.apply()\n",
    "np.random.seed(0)\n",
    "\n",
    "tff.federated_computation(lambda: 'Hello, World!')()\n",
    "# see error meassage at https://github.com/tensorflow/federated/issues/842"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset = emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[0])\n",
    "example_element = next(iter(example_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 20\n",
    "SHUFFLE_BUFFER = 100\n",
    "PREFETCH_BUFFER= 10\n",
    "\n",
    "def preprocess(dataset):\n",
    "\n",
    "  def batch_format_fn(element):\n",
    "    \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
    "    return collections.OrderedDict(\n",
    "        x=tf.reshape(element['pixels'], [-1, 784]), # convert from 28*28 to 784 * 1\n",
    "        y=tf.reshape(element['label'], [-1, 1]))\n",
    "\n",
    "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
    "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('x',\n",
       "              array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "                     [1., 1., 1., ..., 1., 1., 1.],\n",
       "                     [1., 1., 1., ..., 1., 1., 1.],\n",
       "                     ...,\n",
       "                     [1., 1., 1., ..., 1., 1., 1.],\n",
       "                     [1., 1., 1., ..., 1., 1., 1.],\n",
       "                     [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)),\n",
       "             ('y',\n",
       "              array([[4],\n",
       "                     [8],\n",
       "                     [3],\n",
       "                     [2],\n",
       "                     [9],\n",
       "                     [0],\n",
       "                     [8],\n",
       "                     [0],\n",
       "                     [6],\n",
       "                     [6],\n",
       "                     [4],\n",
       "                     [5],\n",
       "                     [4],\n",
       "                     [6],\n",
       "                     [1],\n",
       "                     [2],\n",
       "                     [8],\n",
       "                     [6],\n",
       "                     [1],\n",
       "                     [7]]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_example_dataset = preprocess(example_dataset)\n",
    "\n",
    "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
    "                                     next(iter(preprocessed_example_dataset)))\n",
    "\n",
    "sample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_federated_data(client_data, client_ids):\n",
    "    return [\n",
    "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
    "      for x in client_ids\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In simulation setting, we choose subset of clients randomly. Random subset mighe **slow down convergence**. We will only sample the set of clients once, and reuse the same set across rounds to speed up convergence (intentionally over-fitting to these few user's data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of client datasets: 10\n",
      "First dataset: <PrefetchDataset shapes: OrderedDict([(x, (None, 784)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])>\n"
     ]
    }
   ],
   "source": [
    "sample_clients = emnist_train.client_ids[0:NUM_CLIENTS] # choose first 10 clients\n",
    "\n",
    "federated_train_data = make_federated_data(emnist_train, sample_clients) # preprocessed data for 10 clients\n",
    "\n",
    "print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n",
    "print('First dataset: {d}'.format(d=federated_train_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we first define keras model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Input(shape=(784,)),\n",
    "      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
    "      tf.keras.layers.Softmax(),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- need to convert the keras model to tff learning model interface using :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "  # We _must_ create a new model here, and _not_ capture it from an external\n",
    "  # scope. TFF will call this within different graph contexts.\n",
    "  keras_model = create_keras_model()\n",
    "  return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=preprocessed_example_dataset.element_spec,\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next we can train model calling fed avg algorithm. **Keep in mind that the argument needs to be a constructor (such as model_fn above), not an already-constructed instance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Leyan\\anaconda3\\envs\\audi9\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1659: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Leyan\\anaconda3\\envs\\audi9\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1659: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `client_optimizer` computes the local client update\n",
    "- `server_optimizer` computes the average of local update parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `iterative_process` takes no argument, return a representation of the server status of the federative process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'( -> <model=<trainable=<float32[784,10],float32[10]>,non_trainable=<>>,optimizer_state=<int64>,delta_aggregate_state=<>,model_broadcast_state=<>>@SERVER)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(iterative_process.initialize.type_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we construct server state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `next` represents a single round of Federated Averaging, which consists of pushing the server state (including the model parameters) to the clients, on-device training on their local data, collecting and averaging model updates, and producing a new updated model at the server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " SERVER_STATE, FEDERATED_DATA -> SERVER_STATE, TRAINING_METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1, metrics = OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('sparse_categorical_accuracy', 0.13127571), ('loss', 2.9841821)]))])\n"
     ]
    }
   ],
   "source": [
    "state, metrics = iterative_process.next(state, federated_train_data)\n",
    "print('round 1, metrics = {}'.format(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  2, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('sparse_categorical_accuracy', 0.1382716), ('loss', 2.9017148)]))])\n",
      "round  3, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('sparse_categorical_accuracy', 0.16111112), ('loss', 2.7337723)]))])\n",
      "round  4, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('sparse_categorical_accuracy', 0.16296296), ('loss', 2.7093928)]))])\n",
      "round  5, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('sparse_categorical_accuracy', 0.21090534), ('loss', 2.5592349)]))])\n",
      "round  6, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('sparse_categorical_accuracy', 0.23806584), ('loss', 2.4227028)]))])\n",
      "round  7, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('sparse_categorical_accuracy', 0.2516461), ('loss', 2.3178978)]))])\n",
      "round  8, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('sparse_categorical_accuracy', 0.2654321), ('loss', 2.276034)]))])\n",
      "round  9, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('sparse_categorical_accuracy', 0.29753086), ('loss', 2.129507)]))])\n",
      "round 10, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('sparse_categorical_accuracy', 0.32777777), ('loss', 2.0459938)]))])\n"
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 11\n",
    "for round_num in range(2, NUM_ROUNDS):\n",
    "    state, metrics = iterative_process.next(state, federated_train_data)\n",
    "    print('round {:2d}, metrics={}'.format(round_num, metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"/tmp/logs/scalars/training/\"\n",
    "summary_writer = tf.summary.create_file_writer(logdir)\n",
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROUNDS = 11\n",
    "with summary_writer.as_default():\n",
    "  for round_num in range(1, NUM_ROUNDS):\n",
    "    state, metrics = iterative_process.next(state, federated_train_data)\n",
    "    for name, value in metrics['train'].items():\n",
    "      tf.summary.scalar(name, value, step=round_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 632."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir /tmp/logs/scalars/ --port=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Run this this cell to clean your directory of old output for future graphs from this directory.\n",
    "!rm -R /tmp/logs/scalars/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model variables from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MnistVariables = collections.namedtuple(\n",
    "    'MnistVariables', 'weights bias num_examples loss_sum accuracy_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mnist_variables():\n",
    "  return MnistVariables(\n",
    "      weights=tf.Variable(\n",
    "          lambda: tf.zeros(dtype=tf.float32, shape=(784, 10)),\n",
    "          name='weights',\n",
    "          trainable=True),\n",
    "      bias=tf.Variable(\n",
    "          lambda: tf.zeros(dtype=tf.float32, shape=(10)),\n",
    "          name='bias',\n",
    "          trainable=True),\n",
    "      num_examples=tf.Variable(0.0, name='num_examples', trainable=False),\n",
    "      loss_sum=tf.Variable(0.0, name='loss_sum', trainable=False),\n",
    "      accuracy_sum=tf.Variable(0.0, name='accuracy_sum', trainable=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the forward pass method that computes loss, emits predictions, and updates the cumulative statistics for a single batch of input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_forward_pass(variables, batch):\n",
    "  y = tf.nn.softmax(tf.matmul(batch['x'], variables.weights) + variables.bias)\n",
    "  predictions = tf.cast(tf.argmax(y, 1), tf.int32)\n",
    "\n",
    "  flat_labels = tf.reshape(batch['y'], [-1])\n",
    "  loss = -tf.reduce_mean(\n",
    "      tf.reduce_sum(tf.one_hot(flat_labels, 10) * tf.math.log(y), axis=[1]))\n",
    "  accuracy = tf.reduce_mean(\n",
    "      tf.cast(tf.equal(predictions, flat_labels), tf.float32))\n",
    "\n",
    "  num_examples = tf.cast(tf.size(batch['y']), tf.float32)\n",
    "\n",
    "  variables.num_examples.assign_add(num_examples)\n",
    "  variables.loss_sum.assign_add(loss * num_examples)\n",
    "  variables.accuracy_sum.assign_add(accuracy * num_examples)\n",
    "\n",
    "  return loss, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_mnist_metrics(variables):\n",
    "  return collections.OrderedDict(\n",
    "      num_examples=variables.num_examples,\n",
    "      loss=variables.loss_sum / variables.num_examples,\n",
    "      accuracy=variables.accuracy_sum / variables.num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation\n",
    "def aggregate_mnist_metrics_across_clients(metrics):\n",
    "  return collections.OrderedDict(\n",
    "      num_examples=tff.federated_sum(metrics.num_examples),\n",
    "      loss=tff.federated_mean(metrics.loss, metrics.num_examples),\n",
    "      accuracy=tff.federated_mean(metrics.accuracy, metrics.num_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Construct `tff.learning.model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(tff.learning.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    self._variables = create_mnist_variables()\n",
    "\n",
    "  @property\n",
    "  def trainable_variables(self):\n",
    "    return [self._variables.weights, self._variables.bias]\n",
    "\n",
    "  @property\n",
    "  def non_trainable_variables(self):\n",
    "    return []\n",
    "\n",
    "  @property\n",
    "  def local_variables(self):\n",
    "    return [\n",
    "        self._variables.num_examples, self._variables.loss_sum,\n",
    "        self._variables.accuracy_sum\n",
    "    ]\n",
    "\n",
    "  @property\n",
    "  def input_spec(self):\n",
    "    return collections.OrderedDict(\n",
    "        x=tf.TensorSpec([None, 784], tf.float32),\n",
    "        y=tf.TensorSpec([None, 1], tf.int32))\n",
    "\n",
    "  @tf.function\n",
    "  def forward_pass(self, batch, training=True):\n",
    "    del training\n",
    "    loss, predictions = mnist_forward_pass(self._variables, batch)\n",
    "    num_exmaples = tf.shape(batch['x'])[0]\n",
    "    return tff.learning.BatchOutput(\n",
    "        loss=loss, predictions=predictions, num_examples=num_exmaples)\n",
    "\n",
    "  @tf.function\n",
    "  def report_local_outputs(self):\n",
    "    return get_local_mnist_metrics(self._variables)\n",
    "\n",
    "  @property\n",
    "  def federated_output_computation(self):\n",
    "    return aggregate_mnist_metrics_across_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training in new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    MnistModel,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.9460506), ('accuracy', 0.12119342)]))])\n"
     ]
    }
   ],
   "source": [
    "state, metrics = iterative_process.next(state, federated_train_data)\n",
    "print('round  1, metrics={}'.format(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  2, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.967553), ('accuracy', 0.13765432)]))])\n",
      "round  3, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.7426832), ('accuracy', 0.15884773)]))])\n",
      "round  4, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.69955), ('accuracy', 0.18312757)]))])\n",
      "round  5, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.4934955), ('accuracy', 0.21069959)]))])\n",
      "round  6, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.449169), ('accuracy', 0.22057614)]))])\n",
      "round  7, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.383666), ('accuracy', 0.2399177)]))])\n",
      "round  8, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.2692196), ('accuracy', 0.2771605)]))])\n",
      "round  9, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.1626995), ('accuracy', 0.2888889)]))])\n",
      "round 10, metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('num_examples', 4860.0), ('loss', 2.0614836), ('accuracy', 0.33703703)]))])\n"
     ]
    }
   ],
   "source": [
    "for round_num in range(2, 11):\n",
    "  state, metrics = iterative_process.next(state, federated_train_data)\n",
    "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = tff.learning.build_federated_evaluation(MnistModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = evaluation(state.model, federated_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OrderedDict([('num_examples', 4860.0), ('loss', 1.611347), ('accuracy', 0.47839507)])\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(train_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train on test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " <PrefetchDataset shapes: OrderedDict([(x, (None, 784)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "federated_test_data = make_federated_data(emnist_test, sample_clients)\n",
    "\n",
    "len(federated_test_data), federated_test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = evaluation(state.model, federated_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OrderedDict([('num_examples', 580.0), ('loss', 1.7383928), ('accuracy', 0.44827586)])\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audi9",
   "language": "python",
   "name": "audi9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
